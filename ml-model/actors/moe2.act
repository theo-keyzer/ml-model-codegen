// =========================================================================
// CUDA CODE GENERATION ACTOR SCRIPT FOR TRANSFORMER MOE (FIXED)
// =========================================================================

Actor main

Add.map _:tensor

All Model generate_model_files

// =========================================================================
// MODEL FILE GENERATION
// =========================================================================

Actor generate_model_files Model
C // Generated CUDA inference code for ${model}
C // WARNING: Auto-generated file, do not edit manually
C
C #include <cuda_runtime.h>
C #include <cublas_v2.h>
C #include <cusparse.h>
C #include <stdio.h>
C #include <math.h>
C
C // =========================================================================
C // 1. Tensor Declarations
C // =========================================================================
Its GraphTensor declare_graph_tensor
Its Tensor declare_tensor
C
C // =========================================================================
C // 2. Kernel Forward Declarations
C // =========================================================================
All Kernel declare_kernel_forward
C
C // =========================================================================
C // 3. Operation Forward Declarations
C // =========================================================================
All Op declare_op_forward
All AttentionOp declare_attention_op_forward
All GraphOp declare_graph_op_forward
All StatefulOp declare_stateful_op_forward
All ODEOp declare_ode_op_forward
C
C // =========================================================================
C // 4. Block Definitions
C // =========================================================================
All Block declare_block
C
C // =========================================================================
C // 5. Kernel Implementations
C // =========================================================================
All Kernel generate_kernel_implementation
C
C // =========================================================================
C // 6. Operation Implementations
C // =========================================================================
All Op generate_op_implementation
All AttentionOp generate_attention_op_implementation
All GraphOp generate_graph_op_implementation
All StatefulOp generate_stateful_op_implementation
All ODEOp generate_ode_op_implementation
C
C // =========================================================================
C // 7. Expert Router Implementation
C // =========================================================================
All ExpertRoutingOp generate_expert_router_implementation
C
C // =========================================================================
C // 8. Control Flow Implementation
C // =========================================================================
All ControlFlow generate_control_flow_implementation
C
C // =========================================================================
C // 9. State Management
C // =========================================================================
All StateTransfer generate_state_transfer_implementation
C
C // =========================================================================
C // 10. Continuous Layer (Neural ODE)
C // =========================================================================
All ContinuousLayer generate_continuous_layer_implementation
C
C // =========================================================================
C // 11. Inference Configurations
C // =========================================================================
Its Config generate_config_implementation
C
C // =========================================================================
C // 12. Main Inference Entry Point
C // =========================================================================
C
C int main() {
C     printf("Generated inference code for ${model}\\n");
C     
C     // Initialize CUDA context
C     cudaSetDevice(0);
C     
C     // Create CUDA stream
C     cudaStream_t stream;
C     cudaStreamCreate(&stream);
C     
C     // Initialize cuBLAS and cuSPARSE handles
C     cublasHandle_t cublas_handle;
C     cublasCreate(&cublas_handle);
C     cublasSetStream(cublas_handle, stream);
C     
C     cusparseHandle_t cusparse_handle;
C     cusparseCreate(&cusparse_handle);
C     cusparseSetStream(cusparse_handle, stream);
C     
C     printf("CUDA context initialized\\n");
C     
C     // Cleanup
C     cusparseDestroy(cusparse_handle);
C     cublasDestroy(cublas_handle);
C     cudaStreamDestroy(stream);
C     
C     return 0;
C }

// =========================================================================
// TENSOR DECLARATIONS
// =========================================================================

Actor declare_tensor Tensor
Add.break _.tensor:${tensor:l}
C extern float* ${tensor:l}; // ${shape} ${layout} ${dtype} ${shape_type::static}

Actor declare_graph_tensor GraphTensor
Add.break _.tensor:${graph_tensor:l}
C extern float* ${graph_tensor:l}; // Graph: ${graph_type}, format: ${sparse_format}, nodes: ${num_nodes::dynamic}, edges: ${num_edges::dynamic}

// =========================================================================
// KERNEL FORWARD DECLARATIONS
// =========================================================================

Actor declare_kernel_forward Kernel
C // Kernel: ${kernel}
C ${signature}

// =========================================================================
// OPERATION FORWARD DECLARATIONS
// =========================================================================

Actor declare_op_forward Op
C void op_${parent.layer:l}_${op:l}_forward(void* stream);

Actor declare_attention_op_forward AttentionOp
C void attention_op_${attn_op:l}_forward(void* stream);

Actor declare_graph_op_forward GraphOp
C void graph_op_${graph_op:l}_forward(void* stream, void* cusparse_handle);

Actor declare_stateful_op_forward StatefulOp
C void stateful_op_${state_op:l}_forward(void* stream, bool reset_state);

Actor declare_ode_op_forward ODEOp
C void ode_op_${ode_op:l}_forward(void* stream, float t_start, float t_end);

// =========================================================================
// BLOCK DECLARATIONS
// =========================================================================

Actor declare_block Block
C
C // ============ Block: ${block} ============
C // Type: ${block_type}
C // Description: ${desc}
C // Parameters:
C // From: ${._lno}
C
Its BlockParam declare_block_param
C

Actor declare_block_param BlockParam
C //   ${param}: ${param_type} = ${default::"no default"}

// =========================================================================
// KERNEL IMPLEMENTATIONS
// =========================================================================

Actor generate_kernel_implementation Kernel
C
C // ============ ${kernel} ============
C // Backend: ${backend}
C // Description: ${desc}
C // From: ${._lno}
C
C ${body}
C

// =========================================================================
// OPERATION IMPLEMENTATIONS
// =========================================================================

Actor generate_op_implementation Op kernel_op ??
C
C void op_${parent.layer:l}_${op:l}_forward(void* stream) {
C     // Operation: ${op}
C     // Kernel: ${kernel}
C     // Layer: ${parent.layer}
C     // From: ${._lno}
C
C     // Kernel launch configuration
C     int block_size = 256;
C     int num_elements = 1024; // TODO: Calculate from tensor shapes
C     dim3 block(block_size);
C     dim3 grid((num_elements + block_size - 1) / block_size);
C
C     // Kernel launch
C     ${kernel:l}_kernel<<<grid, block, 0, (cudaStream_t)stream>>>(
Cs        
Its Arg generate_kernel_args
C     );
C
C     cudaStreamSynchronize((cudaStream_t)stream);
C     printf("Executed: ${parent.layer}.${op}\\n");
C }
Break

Actor generate_op_implementation Op
C
C void op_${parent.layer:l}_${op:l}_forward(void* stream) {
C     // Operation: ${op}
C     // Kernel: ${kernel}
C     // Layer: ${parent.layer}
C     // From: ${._lno}
C
C     // 1. Get Operation Dimensions (from KernelOp)
C     ${kernel_op.dimension_calc}
C
C     // 2. Setup Launch Configuration (from KernelOp)
C     int block_size = ${kernel_op.block_size};
C     dim3 block(block_size);
C     dim3 grid(${kernel_op.grid_calc});
C
C     // 3. Kernel Launch
C     ${kernel:l}_kernel<<<grid, block, 0, (cudaStream_t)stream>>>(
Cs        
Its Arg generate_kernel_args
C
C     );
C     cudaStreamSynchronize((cudaStream_t)stream);
C }
Break

Actor generate_kernel_args Arg
Cs ${.1.,} ${tensor.tensor:l}

// =========================================================================
// ATTENTION OPERATION IMPLEMENTATIONS
// =========================================================================

Actor generate_attention_op_implementation AttentionOp
C
C void attention_op_${attn_op:l}_forward(void* stream) {
C     // Attention Operation: ${attn_op}
C     // Type: ${attn_type}
C     // Num Heads: ${num_heads}
C     // Head Dim: ${head_dim}
C     // Causal: ${causal::false}
C     // From: ${._lno}
C
C     // Query, Key, Value tensors
Its parent.Arg attention_get_qkv_tensors
C
C     // Launch multi-head attention kernel
C     int batch = 1;
C     int seq_len = 512; // TODO: Extract from tensor shape
C     int num_heads = ${num_heads};
C     int head_dim = ${head_dim};
C     
C     dim3 block(256);
C     dim3 grid((batch * num_heads * seq_len + 255) / 256);
C
C     attention_kernel<<<grid, block, 0, (cudaStream_t)stream>>>(
Cs         query, key, value, 
Its parent.Arg attention_get_mask
Cs         output,
C         batch, num_heads, seq_len, head_dim, ${causal::false}
C     );
C
C     cudaStreamSynchronize((cudaStream_t)stream);
C     printf("Executed: attention_op_${attn_op:l}\\n");
C }

Actor attention_get_qkv_tensors Arg role = query
C     float* query = ${tensor.tensor:l};

Actor attention_get_qkv_tensors Arg role = key
C     float* key = ${tensor.tensor:l};

Actor attention_get_qkv_tensors Arg role = value
C     float* value = ${tensor.tensor:l};

Actor attention_get_qkv_tensors Arg role = output
C     float* output = ${tensor.tensor:l};

Actor attention_get_mask Arg role = mask
Cs mask, 

-Actor attention_get_mask Arg
-Cs NULL, 

// =========================================================================
// GRAPH OPERATION IMPLEMENTATIONS
// =========================================================================

Actor generate_graph_op_implementation GraphOp
C
C void graph_op_${graph_op:l}_forward(void* stream, void* cusparse_handle) {
C     // Graph Operation: ${graph_op}
C     // GNN Type: ${gnn_type}
C     // Aggregation: ${aggregation}
C     // Num Layers: ${num_layers::1}
C     // From: ${._lno}
C
Its parent.Arg graph_extract_tensors
C
C     // Perform sparse matrix operations using cuSPARSE
C     printf("Executing graph operation: ${gnn_type} with ${aggregation} aggregation\\n");
C
C     // Launch graph kernel
C     for (int layer = 0; layer < ${num_layers::1}; layer++) {
C         dim3 block(256);
C         dim3 grid((num_nodes + 255) / 256);
C
C         gat_kernel<<<grid, block, 0, (cudaStream_t)stream>>>(
Cs             node_feats, 
Its parent.Arg graph_pass_edge_feats
Cs             adjacency, output,
C             num_nodes, num_edges, feature_dim, layer
C         );
C     }
C
C     cudaStreamSynchronize((cudaStream_t)stream);
C     printf("Executed: graph_op_${graph_op:l}\\n");
C }

Actor graph_extract_tensors Arg role = node_features
C     float* node_feats = ${tensor.tensor:l};
C     int num_nodes = ${tensor.shape:0};
C     int feature_dim = ${tensor.shape:1};

Actor graph_extract_tensors Arg role = edge_features
C     float* edge_feats = ${tensor.tensor:l};

Actor graph_extract_tensors Arg role = adjacency
C     float* adjacency = ${tensor.tensor:l};
C     int num_edges = ${tensor.shape:1};

Actor graph_extract_tensors Arg role = node_output
C     float* output = ${tensor.tensor:l};

Actor graph_pass_edge_feats Arg role = edge_features
Cs edge_feats, 

-Actor graph_pass_edge_feats Arg

// =========================================================================
// STATEFUL OPERATION IMPLEMENTATIONS
// =========================================================================

Actor generate_stateful_op_implementation StatefulOp
C
C void stateful_op_${state_op:l}_forward(void* stream, bool reset_state) {
C     // Stateful Operation: ${state_op}
C     // State Type: ${state_type}
C     // Stateful: ${stateful}
C     // From: ${._lno}
C
C     // State tensors
Its parent.Arg stateful_declare_states
C
C     if (reset_state) {
C         // Reset states to zero
-C         int hidden_size = ${.extract_last_dim.${.get_hidden_state_shape}};
-C         int hidden_size = ${tensor.shape:extract_last_dim};
C         cudaMemsetAsync(hidden_state, 0, sizeof(float) * hidden_size, (cudaStream_t)stream);
Its parent.Arg stateful_reset_cell
C         printf("State reset for ${state_op}\\n");
C     }
C
C     // Launch LSTM/GRU kernel
C     int batch = 1;
C     int seq_len = 512; // TODO: Extract from input tensor
-C     int hidden_dim = ${.extract_last_dim.${.get_hidden_state_shape}};
C     int hidden_dim = hidden_size;
C     
C     dim3 block(256);
C     dim3 grid((batch * hidden_dim + 255) / 256);
C
C     ${state_type:l}_kernel<<<grid, block, 0, (cudaStream_t)stream>>>(
Cs        
Its parent.Arg stateful_pass_args
C
C         batch, seq_len, hidden_dim
C     );
C
C     cudaStreamSynchronize((cudaStream_t)stream);
C     printf("Executed: stateful_op_${state_op:l}\\n");
C }


Actor stateful_declare_states Arg role = hidden_state
C     static float* hidden_state = ${tensor.tensor:l};
C     int hidden_size = ${tensor.shape:-1};

Actor stateful_declare_states Arg role = cell_state
C     static float* cell_state = ${tensor.tensor:l};

Actor stateful_declare_states Arg role = input
C     float* input = ${tensor.tensor:l};

Actor stateful_declare_states Arg role = output
C     float* output = ${tensor.tensor:l};

Actor stateful_reset_cell Arg role = cell_state
C         cudaMemsetAsync(cell_state, 0, sizeof(float) * hidden_size, (cudaStream_t)stream);

Actor stateful_pass_args Arg role = input
Cs         input, 

Actor stateful_pass_args Arg role = hidden_state
Cs hidden_state, 

Actor stateful_pass_args Arg role = cell_state
Cs cell_state, 

Actor stateful_pass_args Arg role = output
Cs output, 

// =========================================================================
// ODE OPERATION IMPLEMENTATIONS
// =========================================================================

Actor generate_ode_op_implementation ODEOp
C
C void ode_op_${ode_op:l}_forward(void* stream, float t_start, float t_end) {
C     // ODE Operation: ${ode_op}
C     // Integration Method: ${integration}
C     // Adjoint: ${adjoint::false}
C     // From: ${._lno}
C
Its parent.Arg ode_declare_tensors
C
C     // Launch ODE solver kernel
C     int num_steps = 10; // TODO: Extract from ODE config
C     
C     dim3 block(256);
C     dim3 grid((state_dim + 255) / 256);
C
C     printf("Solving ODE from t=%.2f to t=%.2f using ${integration}\\n", t_start, t_end);
C
C     ode_solver_kernel<<<grid, block, 0, (cudaStream_t)stream>>>(
Cs         state_in, state_out, 
Its parent.Arg ode_pass_time_tensor
C
C         t_start, t_end, state_dim, num_steps, ${adjoint::false}
C     );
C
C     cudaStreamSynchronize((cudaStream_t)stream);
C     printf("Executed: ode_op_${ode_op:l}\\n");
C }

Actor ode_declare_tensors Arg role = state_input
C     float* state_in = ${tensor.tensor:l};
C     int state_dim = ${tensor.shape:-1};

Actor ode_declare_tensors Arg role = state_output
C     float* state_out = ${tensor.tensor:l};

Actor ode_declare_tensors Arg role = time_tensor
C     float* time_pts = ${tensor.tensor:l};

Actor ode_pass_time_tensor Arg role = time_tensor
Cs time_pts, 

-Actor ode_pass_time_tensor Arg
-Cs NULL, 

// =========================================================================
// EXPERT ROUTER IMPLEMENTATIONS
// =========================================================================

Actor generate_expert_router_implementation ExpertRoutingOp
C
C // ============ Expert Router: ${expert_op} ============
C // Num Experts: ${num_experts}
C // Top-K: ${top_k}
C // Load Balance: ${load_balance::"none"}
C // From: ${._lno}
C
C void router_${expert_op:l}_forward(void* stream) {
Its parent.Arg expert_get_gate_tensor
C     
C     // Compute top-k experts per token
C     int num_experts = ${num_experts};
C     int top_k = ${top_k};
C     int batch = 1;
C     int seq_len = 512; // TODO: Extract from tensor
C     
C     dim3 block(256);
C     dim3 grid((batch * seq_len + 255) / 256);
C     
C     printf("Routing to top-%d of %d experts\\n", top_k, num_experts);
C     
C     expert_routing_kernel<<<grid, block, 0, (cudaStream_t)stream>>>(
C         gate_tensor, num_experts, top_k
C     );
C     
C     // Execute selected experts (all experts for now)
Its experts generate_expert_layer_call
C     
C     cudaStreamSynchronize((cudaStream_t)stream);
C     printf("Expert routing complete: ${expert_op}\\n");
C }
C

Actor expert_get_gate_tensor Arg role = gate_tensor
C     float* gate_tensor = ${tensor.tensor:l};

Actor generate_expert_layer_call Layer
C     // Execute expert layer: ${layer}
Its Op generate_expert_op_call

Actor generate_expert_op_call Op
C     op_${parent.layer:l}_${op:l}_forward(stream);

// =========================================================================
// CONTROL FLOW IMPLEMENTATIONS
// =========================================================================

Actor generate_control_flow_implementation ControlFlow
C
C // ============ Control Flow: ${control} ============
C // Type: ${type}
C // Description: ${desc}
C // From: ${._lno}
C
C void control_${control:l}_execute(void* stream) {
C     printf("Executing control flow: ${control} (${type})\\n");
C     
C     // Evaluate condition
Its Condition generate_condition_evaluation
C     
C     // Execute branches based on condition
Its Branch generate_branch_execution
C     
C     printf("Control flow complete: ${control}\\n");
C }
C

Actor generate_condition_evaluation Condition
C     // Condition: ${condition}
C     // Predicate: ${predicate}
Its input generate_condition_input_ref
C     float threshold_val = ${threshold::0.5};
C     
C     // Evaluate predicate
C     bool condition_result = evaluate_${predicate:l}(input_tensor, threshold_val);
C     printf("Condition ${condition}: %s\\n", condition_result ? "true" : "false");

Actor generate_condition_input_ref Tensor
C     float* input_tensor = ${tensor:l};

-Actor generate_condition_input_ref
-C     float* input_tensor = NULL;

Actor generate_branch_execution Branch
C     // Branch ${branch_id}: ${desc::"no description"}
C     if (condition_result ${.branch_condition.${branch_id}}) {
Its layers generate_branch_layer_execution
C     }

Actor generate_branch_layer_execution Layer
C         // Execute layer: ${layer}
Its Op generate_branch_op_execution

Actor generate_branch_op_execution Op
C         op_${parent.layer:l}_${op:l}_forward(stream);

// =========================================================================
// STATE TRANSFER IMPLEMENTATIONS
// =========================================================================

Actor generate_state_transfer_implementation StateTransfer
C
C // ============ State Transfer: ${transfer} ============
C // Policy: ${policy}
C // Trigger: ${trigger}
C // From: ${._lno}
C
C void state_transfer_${transfer:l}(void* stream) {
Its source_state generate_state_source_ref
Its target_state generate_state_target_ref
C     
C     int state_size = 768; // TODO: Extract from tensor shape
C     
C     printf("State transfer: ${policy} on ${trigger}\\n");
C     
C     if (strcmp("${policy}", "keep") == 0) {
C         // Keep source state intact
C         printf("Keeping state as-is\\n");
C     } else if (strcmp("${policy}", "reset") == 0) {
C         // Reset target state to zero
C         cudaMemsetAsync(target, 0, sizeof(float) * state_size, (cudaStream_t)stream);
C         printf("Reset state to zero\\n");
C     } else if (strcmp("${policy}", "transfer") == 0) {
C         // Copy source to target
C         cudaMemcpyAsync(target, source, sizeof(float) * state_size, 
C                        cudaMemcpyDeviceToDevice, (cudaStream_t)stream);
C         printf("Transferred state\\n");
C     }
C     
C     cudaStreamSynchronize((cudaStream_t)stream);
C }
C

Actor generate_state_source_ref Tensor
C     float* source = ${tensor:l};

Actor generate_state_target_ref Tensor
C     float* target = ${tensor:l};

// =========================================================================
// CONTINUOUS LAYER (NEURAL ODE) IMPLEMENTATIONS
// =========================================================================

Actor generate_continuous_layer_implementation ContinuousLayer
C
C // ============ Continuous Layer: ${cont_layer} ============
C // Solver: ${solver}
C // Time Range: [${t_start}, ${t_end}]
C // Time Steps: ${time_steps::10}
C // Adaptive: ${adaptive::false}
C // Tolerance: ${tolerance::0.001}
C // From: ${._lno}
C
C void continuous_layer_${cont_layer:l}_forward(void* stream) {
C     printf("Neural ODE: ${solver} solver, t=[${t_start}, ${t_end}]\\n");
C     
C     float t_start = ${t_start};
C     float t_end = ${t_end};
C     int time_steps = ${time_steps::10};
C     float dt = (t_end - t_start) / time_steps;
C     bool adaptive = ${adaptive::false};
C     
C     if (adaptive) {
C         printf("Using adaptive stepping with tolerance ${tolerance::0.001}\\n");
C     }
C
C     // Execute dynamics function iteratively
Its dynamics generate_dynamics_execution
C     
C     printf("Neural ODE complete: ${cont_layer}\\n");
C }
C

Actor generate_dynamics_execution Layer
C     // Dynamics function: ${layer}
C     for (int step = 0; step < time_steps; step++) {
C         float t = t_start + step * dt;
Its Op generate_dynamics_op_execution
C         printf("ODE step %d, t=%.4f\\n", step, t);
C     }

Actor generate_dynamics_op_execution Op
C         op_${parent.layer:l}_${op:l}_forward(stream);

// =========================================================================
// CONFIGURATION IMPLEMENTATIONS
// =========================================================================

Actor generate_config_implementation Config
C
C // ============ Configuration: ${config} ============
C // Target: ${target}
C // Batch: ${batch}
C // Optimization: ${opt_flags::"none"}
C // Description: ${desc}
C // From: ${._lno}
C
C void inference_${config:l}(float* input, float* output, void* stream) {
C     printf("Starting inference: ${config}\\n");
C     printf("Target: ${target}, Batch: ${batch}\\n");
C     
C     // Initialize any stateful components
All StatefulOp generate_stateful_init
C     
C     // Execute schedule
Its Schedule generate_schedule_execution
C     
C     printf("Inference complete: ${config}\\n");
C }

Actor generate_stateful_init StatefulOp
C     // Initialize stateful op: ${state_op}
C     stateful_op_${state_op:l}_forward(stream, true);


Actor generate_schedule_execution Schedule control ??
C     // Step ${seq}: ${desc}
Its layer generate_schedule_layer_call
Its op generate_schedule_op_call
Break

Actor generate_schedule_execution Schedule
C     // Step ${seq}: ${desc}
Its control generate_control_flow_call
Break


Actor generate_schedule_layer_call Layer
C     // Execute all ops in layer: ${layer}
Its Op generate_schedule_layer_op_call

Actor generate_schedule_layer_op_call Op
C     op_${parent.layer:l}_${op:l}_forward(stream);

Actor generate_schedule_op_call Op
C     op_${parent.layer:l}_${op:l}_forward(stream);

Actor generate_control_flow_call ControlFlow
C     control_${control:l}_execute(stream);


